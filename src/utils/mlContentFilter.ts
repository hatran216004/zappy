import * as tf from '@tensorflow/tfjs';

/**
 * Vocabulary t·ª´ c√°c t·ª´ kh√≥a kh√¥ng l√†nh m·∫°nh v√† c√°c t·ª´ th√¥ng th∆∞·ªùng
 * ƒê∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t·∫°o feature vector
 */
const VOCABULARY = [
  // T·ª´ kh√¥ng l√†nh m·∫°nh
  'dcm',
  'dkm',
  'clmm',
  'clgt',
  'vl',
  'dm',
  'cl',
  'djtme',
  'djt',
  'dcmm',
  'fuck',
  'fucking',
  'fucked',
  'fucker',
  'shit',
  'damn',
  'bitch',
  'ass',
  'asshole',
  'bastard',
  'crap',
  'piss',
  'hell',
  'dick',
  'cock',
  'pussy',
  'sex',
  'sexual',
  'sexy',
  'porn',
  'porno',
  'pornography',
  'xxx',
  'nsfw',
  'nude',
  'naked',
  'idiot',
  'stupid',
  'moron',
  'retard',
  'hate',
  'kill',
  'murder',
  'death',
  'drug',
  'suicide',
  'die',
  // T·ª´ th√¥ng th∆∞·ªùng (ƒë·ªÉ t·∫°o context)
  'hello',
  'hi',
  'thanks',
  'thank',
  'you',
  'good',
  'nice',
  'great',
  'like',
  'love',
  'happy',
  'sad',
  'angry',
  'time',
  'day',
  'today',
  'tomorrow',
  'friend',
  'people',
  'think',
  'know',
  'see',
  'look',
  'come',
  'go',
  'get',
  'make',
  'take',
  'give',
  'say',
  'tell',
  'ask',
  'help',
  'work',
  'play',
  'eat',
  'drink',
  'sleep',
  'wake',
  'home',
  'house',
  'car',
  'book',
  'read',
  'write',
  'learn',
  'study',
  'school',
  'work',
  'job',
  'money',
  'buy',
  'sell'
];

const VOCAB_SIZE = VOCABULARY.length;
const MAX_SEQUENCE_LENGTH = 50; // ƒê·ªô d√†i t·ªëi ƒëa c·ªßa c√¢u

/**
 * T·∫°o feature vector t·ª´ text s·ª≠ d·ª•ng bag-of-words
 */
function textToVector(text: string): number[] {
  const normalized = normalizeText(text);
  const words = normalized.split(/\s+/);
  const vector = new Array(VOCAB_SIZE).fill(0);

  words.forEach((word) => {
    const index = VOCABULARY.indexOf(word);
    if (index !== -1) {
      vector[index] += 1;
    }
  });

  // Normalize vector
  const sum = vector.reduce((a, b) => a + b, 0);
  if (sum > 0) {
    return vector.map((v) => v / sum);
  }
  return vector;
}

/**
 * Chu·∫©n h√≥a text
 */
function normalizeText(text: string): string {
  return text
    .toLowerCase()
    .normalize('NFD')
    .replace(/[\u0300-\u036f]/g, '')
    .replace(/[^\w\s]/g, ' ')
    .replace(/\s+/g, ' ')
    .trim();
}

/**
 * T·∫°o model ƒë∆°n gi·∫£n ƒë·ªÉ ph√¢n lo·∫°i n·ªôi dung
 */
export function createModel(): tf.Sequential {
  const model = tf.sequential({
    layers: [
      // Input layer
      tf.layers.dense({
        inputShape: [VOCAB_SIZE],
        units: 64,
        activation: 'relu',
        name: 'dense1'
      }),
      tf.layers.dropout({ rate: 0.3 }),
      // Hidden layer
      tf.layers.dense({
        units: 32,
        activation: 'relu',
        name: 'dense2'
      }),
      tf.layers.dropout({ rate: 0.3 }),
      // Output layer (binary classification: 0 = safe, 1 = unsafe)
      tf.layers.dense({
        units: 1,
        activation: 'sigmoid',
        name: 'output'
      })
    ]
  });

  model.compile({
    optimizer: 'adam',
    loss: 'binaryCrossentropy',
    metrics: ['accuracy']
  });

  return model;
}

/**
 * Train model v·ªõi d·ªØ li·ªáu m·∫´u
 * L∆∞u √Ω: Trong production, n√™n train model v·ªõi dataset l·ªõn h∆°n
 */
export async function trainModel(model: tf.Sequential): Promise<void> {
  // D·ªØ li·ªáu training m·∫´u (safe = 0, unsafe = 1)
  const trainingData = [
    // Safe examples - m·ªü r·ªông dataset
    { text: 'hello how are you', label: 0 },
    { text: 'this is a nice day', label: 0 },
    { text: 'thanks for your help', label: 0 },
    { text: 'i like this post', label: 0 },
    { text: 'great work keep it up', label: 0 },
    { text: 'have a good day', label: 0 },
    { text: 'see you tomorrow', label: 0 },
    { text: 'what do you think', label: 0 },
    { text: 'i love this', label: 0 },
    { text: 'nice to meet you', label: 0 },
    { text: 'that is interesting', label: 0 },
    { text: 'i agree with you', label: 0 },
    { text: 'good morning everyone', label: 0 },
    { text: 'have a nice weekend', label: 0 },
    { text: 'looking forward to it', label: 0 },
    { text: 'thanks for sharing', label: 0 },
    { text: 'this is helpful', label: 0 },
    { text: 'i understand now', label: 0 },
    { text: 'great job on this', label: 0 },
    { text: 'keep up the good work', label: 0 },
    // Edge cases - c√≥ th·ªÉ b·ªã nh·∫ßm
    { text: 'kill time', label: 0 }, // "kill time" l√† an to√†n
    { text: 'sex education', label: 0 }, // Context quan tr·ªçng
    { text: 'drug store', label: 0 }, // "drug store" l√† an to√†n
    // Unsafe examples
    { text: 'fuck you', label: 1 },
    { text: 'this is shit', label: 1 },
    { text: 'you are an idiot', label: 1 },
    { text: 'dcm you', label: 1 },
    { text: 'kill yourself', label: 1 },
    { text: 'this is porn', label: 1 },
    { text: 'fucking stupid', label: 1 },
    { text: 'damn it', label: 1 },
    { text: 'you bitch', label: 1 },
    { text: 'dkm', label: 1 },
    { text: 'fuck off', label: 1 },
    { text: 'go to hell', label: 1 },
    { text: 'you are stupid', label: 1 },
    { text: 'this is fucking bad', label: 1 },
    { text: 'dcm may', label: 1 },
    { text: 'clmm', label: 1 },
    { text: 'you are a moron', label: 1 },
    { text: 'shut up bitch', label: 1 },
    { text: 'fuck this shit', label: 1 },
    { text: 'damn you', label: 1 }
  ];

  const xs: number[][] = [];
  const ys: number[] = [];

  trainingData.forEach((item) => {
    xs.push(textToVector(item.text));
    ys.push(item.label);
  });

  const xsTensor = tf.tensor2d(xs);
  const ysTensor = tf.tensor2d(ys, [ys.length, 1]);

  await model.fit(xsTensor, ysTensor, {
    epochs: 100,
    batchSize: 8,
    validationSplit: 0.2,
    verbose: 0
  });

  xsTensor.dispose();
  ysTensor.dispose();
}

/**
 * D·ª± ƒëo√°n xem n·ªôi dung c√≥ kh√¥ng l√†nh m·∫°nh kh√¥ng
 * @param model Model ƒë√£ ƒë∆∞·ª£c train
 * @param text Text c·∫ßn ki·ªÉm tra
 * @returns Probability (0-1) c·ªßa vi·ªác n·ªôi dung kh√¥ng l√†nh m·∫°nh
 */
export async function predict(
  model: tf.Sequential,
  text: string
): Promise<number> {
  const vector = textToVector(text);
  const input = tf.tensor2d([vector]);
  const prediction = model.predict(input) as tf.Tensor;
  const value = await prediction.data();
  input.dispose();
  prediction.dispose();
  return value[0];
}

/**
 * Singleton model instance
 */
let modelInstance: tf.Sequential | null = null;
let isModelReady = false;

/**
 * Kh·ªüi t·∫°o v√† train model (ch·ªâ ch·∫°y m·ªôt l·∫ßn)
 */
export async function initializeModel(): Promise<void> {
  if (isModelReady && modelInstance) {
    return;
  }

  try {
    console.log('ü§ñ Initializing ML content filter model...');
    modelInstance = createModel();
    await trainModel(modelInstance);
    isModelReady = true;
    console.log('‚úÖ ML model ready');
  } catch (error) {
    console.error('‚ùå Error initializing ML model:', error);
    // Fallback to rule-based only
    isModelReady = false;
  }
}

/**
 * Ki·ªÉm tra n·ªôi dung s·ª≠ d·ª•ng ML model
 * @param text Text c·∫ßn ki·ªÉm tra
 * @param threshold Ng∆∞·ª°ng ƒë·ªÉ x√°c ƒë·ªãnh kh√¥ng l√†nh m·∫°nh (m·∫∑c ƒë·ªãnh 0.5)
 * @returns true n·∫øu n·ªôi dung kh√¥ng l√†nh m·∫°nh
 */
export async function containsProfanityML(
  text: string,
  threshold: number = 0.5
): Promise<boolean> {
  if (!isModelReady || !modelInstance) {
    // Fallback n·∫øu model ch∆∞a s·∫µn s√†ng
    return false;
  }

  try {
    const probability = await predict(modelInstance, text);
    return probability >= threshold;
  } catch (error) {
    console.error('Error in ML prediction:', error);
    return false;
  }
}

/**
 * L·∫•y model instance (n·∫øu c·∫ßn)
 */
export function getModel(): tf.Sequential | null {
  return modelInstance;
}
